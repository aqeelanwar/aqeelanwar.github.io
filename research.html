<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<title>Aqeel Anwar</title>
	<!-- <script src="https://kit.fontawesome.com/84e2fbe91d.js" crossorigin="anonymous"></script> -->
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	<!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> -->


	<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/fontawesome.min.css" integrity="sha384-jLKHWM3JRmfMU0A5x5AkjWkw/EYfGUAGagvnfryNV3F9VqM98XiIH7VBGVoxVSc7" crossorigin="anonymous"> -->

</head>

<body class="is-preload">

	<!-- Wrapper -->
	<div id="wrapper">

		<!-- Header -->
		<header id="header" class="alt">
			<span class="logo"><img src="images/logo.png" alt="" /></span>
			<h1>Aqeel Anwar</h1>
			<h3>Machine Learning Engineer | Researcher | Top AI Writer on Medium | Traveler</h3>
			<p><a href="https://twitter.com/_aqeelanwar" class="icon brands fa-twitter"> Twitter </a> |
				<a href="https://www.linkedin.com/in/aqeelanwarmalik/" class="icon brands fa-linkedin-in"> LinkedIn </a>|
				<a href="https://scholar.google.com/citations?user=Mpwfoy0AAAAJ" class="icon solid fa-graduation-cap"> Scholar </a>|
				<a href="https://medium.com/@aqeel-anwar" class="icon brands fa-medium-m"> Medium</a>
			</p>
		</header>

		<!-- Nav -->
		<nav id="nav">
			<ul>
				<li><a href="index.html#intro">Introduction</a></li>
				<li><a href="index.html#work">Work Experience</a></li>
				<li><a href="index.html#research" class="active">Education & Research</a></li>
				<li><a href="techblog.html">Tech Blog</a></li>
				<li><a href="travel.html">Travel</a></li>
			</ul>
		</nav>

		<!-- Main -->
		<div id="main">

			<!-- First Section -->
			<section id="first" class="main special">
				<header class="major">
					<h2 class="icon solid fa-book-reader"> Research Experience</h2>
				</header>
				<ul class="alt" align="justify">
					<li>
						<h3><b>Multi-task Federated Reinforcement Learning</b></h3>
						<p><span class="image left"><img src="images/research/R-mtfedrl.png" alt="" /></span>A decentralized policy gradient approach at
							learning a unified
							policy on multi-task RL problems. By combining consensus optimization
							with the policy gradient algorithm, we theoretically show the convergence of the multi-task algorithm. Currently working on the
							effects of adversaries in the MT-FedRL problem and proposing solutions to it. We argue that the common attack methods are not
							guaranteed to carry out a successful attack on Multi-task Federated Reinforcement Learning and propose an adaptive attack method
							with better attack performance. Furthermore, we modify the conventional federated reinforcement learning algorithm to address the
							issue of adversaries that works equally well with and without the adversaries.</br>
							<b>Relevant Papers:</b>
							<code><a href="https://arxiv.org/abs/2006.04338">[UAI2021]</a></code>,
							<code><a href="https://arxiv.org/abs/2103.06473">[arXiv2021]</a></code>,
							<code><a href="https://arxiv.org/pdf/2203.07276.pdf">[DATE2022]</a></code>
						</p>
					</li>

					<li>
						<h3><b>RAPID-RL: A Reconfigurable Architecture with Preemptive-Exits for Efficient Deep-Reinforcement Learning</b></h3>
						<p><span class="image left"><img src="images/research/R-rapidrl.png" alt="" /></span>

							Present-day Deep Reinforcement Learning (RL) systems show great promise towards building intelligent agents surpassing human-level
							performance. However, the computational complexity associated with the underlying deep neural networks (DNNs) leads to power-hungry
							implementations. This makes deep RL systems unsuitable for deployment on resource-constrained edge devices. To address this
							challenge, we propose a reconfigurable architecture with preemptive exits for efficient deep RL (RAPID-RL). RAPID-RL enables
							conditional activation of DNN layers based on the difficulty level of inputs. This allows to dynamically adjust the compute effort
							during inference while maintaining competitive performance.
							</br>
							<b>Relevant Papers:</b>
							<code><a href="https://arxiv.org/abs/2109.08231">[ICRA2022]</a></code>
						</p>
					</li>

					<li>
						<h3><b>Processing-In-Memory based DNN accelerator</b></h3>
						<p><span class="image left"><img src="images/research/R-PIM.png" alt="" /></span>

							Novel STT-MRAM based analogue Processing-In-Memory modular DNN accelerator providing end-to-end simulation framework that is
							required to find a power-performance optimized solution a given DNN topology. The simulator supports various layer types, logical to
							physical crossbar mapping schemes and crossbar configurations. A list of control parameters is used to overwrite DRAM read/write
							bandwidth, number of parallel inputs for pipe-lining and to select mapping scheme. The simulator can be used to design an
							accelerator
							for a given DNN. Results are compared to pure digital custom ASIC implementation showing orders of magnitude improvements in
							power-performance on widely accepted MLPerf benchmarks.
							</br>
							<b>Relevant Papers:</b>
							<code><a href="https://ieeexplore.ieee.org/document/9073792">[AICAS2020]</a></code>,
							<code><a href="https://patentimages.storage.googleapis.com/48/08/a4/e95c290fed8a1e/US20210124984A1.pdf">[Patent-1]</a></code>,
							<code><a href="https://patentimages.storage.googleapis.com/4d/4d/d0/a742dbfdca2c25/US20210124588A1.pdf">[Patent-2]</a></code>
						</p>
					</li>
					<li>
						<h3><b>Hierarchical RL mapped onto Hierarchical memory sub-system</b></h3>
						<p><span class="image left"><img src="images/research/R-HRL.png" alt="" /></span>

							This work presents a transfer learning (TL) followed by reinforcement learning (RL) algorithm mapped onto a hierarchical embedded
							memory system to meet the stringent power budgets of autonomous drones. The power reduction is achieved by 1. TL on
							meta-environments followed by online RL only on the last few layers of a deep convolutional neural network (CNN) instead of
							end-to-end (E2E) RL and 2. Mapping of the algorithm onto a memory hierarchy where the pre-trained weights of all the conv layers and
							the first few fully connected (FC) layers are stored in dense, low standby leakage Spin Transfer Torque (STT) RAM eNVM arrays and
							the weights of the last few FC layers are stored in the on-die SRAM.
							</br>
							<b>Relevant Papers:</b> <code><a href="https://ieeexplore.ieee.org/document/8600838">[M2VIP2018]</a></code>,
							<code><a href="https://arxiv.org/abs/1910.05547">[IEEE-ACCESS2019]</a></code>,
							<code><a href="https://ieeexplore.ieee.org/document/8782629">[JETCAS2019]</a></code>,
							<code><a href="https://ieeexplore.ieee.org/document/8715066">[DATE2019]</a></code>
						</p>
					</li>
					<li>
						<h3><b>RL based drone autonomous navigation</b></h3>
						<p>
							<span class="image left"><img src="images/research/R-DRL.png" alt="" /></span>
							Smart and agile drones are fast becoming ubiquitous at the edge of the cloud. The usage of these drones is constrained by their
							limited power and compute capability. In this work, we explore a Transfer Learning (TL) based approach to reduce the onboard
							computation required to train a deep neural network for autonomous navigation via Deep Reinforcement Learning for a target
							algorithmic performance. A library of 3D realistic meta-environments is manually designed using Unreal Gaming Engine and the network
							is trained end-to-end. These trained meta-weights are then used as initializers to the network in a test environment and fine-tuned
							for the last few fully connected layers.

							</br>
							<b>Relevant Papers:</b> <code><a href="https://ieeexplore.ieee.org/document/8600838">[M2VIP2018]</a></code>,
							<code><a href="https://arxiv.org/abs/1910.05547">[IEEE-ACCESS2019]</a></code>,
							<code><a href="https://ieeexplore.ieee.org/document/8782629">[JETCAS2019]</a></code>,
							<code><a href="https://ieeexplore.ieee.org/document/8715066">[DATE2019]</a></code>
						</p>
					</li>
				</ul>
				<ul class="actions special">
					<li><a href="https://scholar.google.com/citations?user=Mpwfoy0AAAAJ" class="button primary fit">Learn More</a></li>
				</ul>
			</section>

			<section id="second" class="main special">
				<header class="major">
					<h2 class="icon solid fa-code-branch"> Open Source Tools</h2>
				</header>
				<ul class="alt" align="justify">
					<li>
						<h3><b>PEDRA - Programmable Engine for Drone RL Applications</b></h3>
						<p><span class="image left"><img src="images/research/R-pedra.png" alt="" /></span>

							PEDRA is a programmable engine for Drone Reinforcement Learning (RL) applications. The engine is developed in Python and is
							module-wise programmable. PEDRA is targeted mainly at goal-oriented RL problems for drones, but can also be extended to other
							problems. The engine interfaces with Unreal gaming engine using AirSim to create the complete platform. PEDRA comes equip with a
							list of rich 3D realistic environments created using Unreal Gaming Engine that can be used for the underlying drone problem.
							Different level of details are added to make the environments look as realistic as possible. PEDRA is built
							onto the low level python modules provided by AirSim creating higher level python modules for the purpose of drone RL
							applications.</br>
							<b>Download:</b> <code><a href="https://sites.google.com/view/pedra">[Website]</a></code>,
							<code><a href="https://github.com/aqeelanwar/PEDRA">[GitHub]</a></code>
						</p>
					</li>
					<li>
						<h3><b>MaskTheFace</b></h3>
						<p><span class="image left"><img src="images/research/R-MaskTheFace.png" alt="" /></span>MaskTheFace is computer vision-based script to
							mask
							faces in images. It uses a dlib based face landmarks detector to identify the face tilt and six key features of the face necessary
							for applying mask. Based on the face tilt, corresponding mask template is selected from the library of mask. The template mask is
							then transformed based on the six key features to fit perfectly on the face.</br>
							<b>Download:</b>
							<code><a href="http://www.masktheface.aqeel-anwar.com/">[Website]</a></code>,
							<code><a href="https://github.com/aqeelanwar/MaskTheFace">[GitHub]</a></code>
						</p>
					</li>
				</ul>
			</section>

		</div>

		<!-- Footer -->
		<footer id="footer">
			<p class="copyright">&copy; Aqeel Anwar. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
		</footer>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>